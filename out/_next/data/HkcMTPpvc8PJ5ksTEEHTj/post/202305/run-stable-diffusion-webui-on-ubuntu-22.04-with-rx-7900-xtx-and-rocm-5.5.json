{"pageProps":{"postData":{"yyyymm":"202305","name":"run-stable-diffusion-webui-on-ubuntu-22.04-with-rx-7900-xtx-and-rocm-5.5","contentHtml":"<h1 id=\"run-stable-diffusion-webui-on-ubuntu-2204-with-rx-7900-xtx-and-rocm-55\"><a aria-hidden=\"true\" tabindex=\"-1\" href=\"#run-stable-diffusion-webui-on-ubuntu-2204-with-rx-7900-xtx-and-rocm-55\"><span class=\"icon icon-link\"></span></a>Run stable-diffusion-webui on Ubuntu 22.04 with RX 7900 XTX and ROCm 5.5</h1>\n<p>Yesterday I was regularly checking ROCm PRs, and surprised to discover that the ROCm 5.5.0 release notes had been merged, providing official support for my RTX 7900 XTX after a weeks-long wait. I can't wait to test it out.</p>\n<h2 id=\"prerequisites\"><a aria-hidden=\"true\" tabindex=\"-1\" href=\"#prerequisites\"><span class=\"icon icon-link\"></span></a>Prerequisites</h2>\n<h3 id=\"install-amdgpu-driver\"><a aria-hidden=\"true\" tabindex=\"-1\" href=\"#install-amdgpu-driver\"><span class=\"icon icon-link\"></span></a>Install AMDGPU driver</h3>\n<pre><code class=\"language-bash\"># grab the latest amdgpu-install package\ncurl -O https://repo.radeon.com/amdgpu-install/5.5/ubuntu/jammy/amdgpu-install_5.5.50500-1_all.deb\n\nsudo dpkg -i amdgpu-install_5.5.50500-1_all.deb\n\n# install AMDGPU with ROCm support (which is now 5.5.0)\nsudo amdgpu-install --usecase=graphics,rocm\n\n# you should see rocm-5.5.0 here\nls -l /opt\n\n# grant device access to current user\n# log in again or reboot should guarantee it works\nsudo usermod -aG video $USER\nsudo usermod -aG render $USER\n\n# check rocm info, eg. the architecture\nsudo rocminfo\n# nvidia-smi alike\nrocm-smi\n</code></pre>\n<h3 id=\"install-ubuntu-dependencies\"><a aria-hidden=\"true\" tabindex=\"-1\" href=\"#install-ubuntu-dependencies\"><span class=\"icon icon-link\"></span></a>Install Ubuntu dependencies</h3>\n<pre><code class=\"language-bash\"># correct me if anything is missing\nsudo apt install build-essential\n\nsudo apt install python3-pip python3-venv\n\n# fix &#x3C;cmath> not found\nsudo apt install libstdc++-12-dev\n\n# optional, suppress warnings from torchvision\nsudo apt install libpng-dev libjpeg-dev\n</code></pre>\n<h3 id=\"enter-venv-environment\"><a aria-hidden=\"true\" tabindex=\"-1\" href=\"#enter-venv-environment\"><span class=\"icon icon-link\"></span></a>Enter venv environment</h3>\n<pre><code class=\"language-bash\"># can be anywhere you prefer\nmkdir ~/stable-diffusion\ncd ~/stable-diffusion\n\npython3 -m venv venv\n\n# activate venv\nsource venv/bin/activate\n</code></pre>\n<h3 id=\"compile-pytorch-200\"><a aria-hidden=\"true\" tabindex=\"-1\" href=\"#compile-pytorch-200\"><span class=\"icon icon-link\"></span></a>Compile pytorch 2.0.0</h3>\n<pre><code class=\"language-bash\"># must be in venv\ncd ~/stable-diffusion\nsource venv/bin/activate\n\ncurl -L -O https://github.com/pytorch/pytorch/releases/download/v2.0.0/pytorch-v2.0.0.tar.gz\ntar -xzvf pytorch-v2.0.0.tar.gz\n\ncd pytorch-v2.0.0\n\n# update the path to yours\nexport CMAKE_PREFIX_PATH=\"%HOME/stable-diffusion/venv\"\n\nexport PYTORCH_ROCM_ARCH=gfx1100\nexport USE_CUDA=0\n\npip install cmake ninja\npip install -r requirements.txt\npip install mkl mkl-include\npython3 tools/amd_build/build_amd.py\npython3 setup.py install\n</code></pre>\n<h3 id=\"test-pytorch-functionality\"><a aria-hidden=\"true\" tabindex=\"-1\" href=\"#test-pytorch-functionality\"><span class=\"icon icon-link\"></span></a>Test pytorch functionality</h3>\n<p>Run <code>python3</code> and try these out:</p>\n<pre><code class=\"language-python\"># taken from https://github.com/RadeonOpenCompute/ROCm/issues/1930\nimport torch\ntorch.cuda.is_available()\ntorch.cuda.device_count()\ntorch.cuda.current_device()\ntorch.cuda.get_device_name(torch.cuda.current_device())\n\ntensor = torch.randn(2, 2)\nres = tensor.to(0)\n# if it crashes, check this:\n# https://github.com/RadeonOpenCompute/ROCm/issues/1930\nprint(res)\n</code></pre>\n<p>Or you can run <code>./test/run_test.py</code>, which I have failed in <code>test/profiler/test_profiler.py</code>, but it doesn't affect <code>stable-diffusion-webui</code> (hopefully).</p>\n<h3 id=\"compile-torchvision-0151\"><a aria-hidden=\"true\" tabindex=\"-1\" href=\"#compile-torchvision-0151\"><span class=\"icon icon-link\"></span></a>Compile torchvision 0.15.1</h3>\n<pre><code class=\"language-bash\"># must be in venv\ncd ~/stable-diffusion\nsource venv/bin/activate\n\ncurl -L -O https://github.com/pytorch/vision/archive/refs/tags/v0.15.1.tar.gz\ntar -xzvf v0.15.1.tar.gz\n\ncd vision-0.15.1\n\n# update the path to yours\nexport CMAKE_PREFIX_PATH=\"%HOME/stable-diffusion/venv\"\n\n# might be optional\nexport PYTORCH_ROCM_ARCH=gfx1100\nexport USE_CUDA=0\n\npython3 setup.py install\n</code></pre>\n<h3 id=\"set-up-stable-diffusion-webui\"><a aria-hidden=\"true\" tabindex=\"-1\" href=\"#set-up-stable-diffusion-webui\"><span class=\"icon icon-link\"></span></a>Set up stable-diffusion-webui</h3>\n<pre><code class=\"language-bash\"># must be in venv\ncd ~/stable-diffusion\nsource venv/bin/activate\n\ngit clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n\ncd stable-diffusion-webui\n\n# remove torch from requirements.txt\n# idk if it is ok to skip\nsed '/torch/d' requirements.txt\n\npip install -r requirements.txt\n\n# might not be needed if there is only one gpu\nexport HIP_VISIBLE_DEVICES=0\n\npython3 launch.py\n</code></pre>\n<h3 id=\"caveats\"><a aria-hidden=\"true\" tabindex=\"-1\" href=\"#caveats\"><span class=\"icon icon-link\"></span></a>Caveats</h3>\n<blockquote>\n<p><code>CodeFormer</code> will raise exception when checking <code>pytorch</code>'s version, which is <code>2.0.0a0</code>, thus face restoration is unavailable for now.</p>\n</blockquote>\n<h3 id=\"conclusions\"><a aria-hidden=\"true\" tabindex=\"-1\" href=\"#conclusions\"><span class=\"icon icon-link\"></span></a>Conclusions</h3>\n<p>At first, I was building <code>pytorch</code> in Docker, with <a href=\"https://hub.docker.com/layers/rocm/composable_kernel/ck_ub20.04_rocm5.5/images/sha256-7ecc3b5e2e0104a58188ab5f26085c31815d2ed03955d66b805fc10d9e1f6873?context=explore\">rocm/composable_kernel:ck_ub20.04_rocm5.5</a> as the base, but I encountered Segmentation Fault and didn't have the time to try again. Hopefully <a href=\"https://hub.docker.com/r/rocm/pytorch\">rocm/pytorch</a> will update in recent days too.</p>\n<p>Compared to ROCm 5.5 RC4 in Docker, ROCm 5.5 + bare installation does improve in stability and VRAM management. Performance can be optimized further, but I am satisfied now.</p>\n<h2 id=\"references\"><a aria-hidden=\"true\" tabindex=\"-1\" href=\"#references\"><span class=\"icon icon-link\"></span></a>References</h2>\n<ul>\n<li>https://gist.github.com/In-line/c1225f05d5164a4be9b39de68e99ee2b</li>\n<li>https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/9591</li>\n<li>https://github.com/RadeonOpenCompute/ROCm/issues/1930</li>\n</ul>","title":"Run stable-diffusion-webui on Ubuntu 22.04 with RX 7900 XTX and ROCm 5.5"}},"__N_SSG":true}