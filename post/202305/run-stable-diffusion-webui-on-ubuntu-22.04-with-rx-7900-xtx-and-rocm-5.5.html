<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><title>Run stable-diffusion-webui on Ubuntu 22.04 with RX 7900 XTX and ROCm 5.5</title><meta name="next-head-count" content="3"/><meta name="description" content="Generated by create next app"/><link rel="icon" href="/favicon.ico"/><link rel="preload" href="/_next/static/css/dc76b23cea82c435.css" as="style"/><link rel="stylesheet" href="/_next/static/css/dc76b23cea82c435.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee7e63bc15b31913.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-f11614d8aa7ee555.js" defer=""></script><script src="/_next/static/chunks/pages/_app-95d34612df878707.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5B...routes%5D-3240d32ee1486cbf.js" defer=""></script><script src="/_next/static/HkcMTPpvc8PJ5ksTEEHTj/_buildManifest.js" defer=""></script><script src="/_next/static/HkcMTPpvc8PJ5ksTEEHTj/_ssgManifest.js" defer=""></script></head><body><div class="flex min-h-screen w-screen items-center justify-center"><div id="__next"><main class="container m-4 flex max-w-[100vw] flex-col items-stretch gap-4 rounded-lg bg-white p-4 shadow-lg sm:m-8 sm:p-8"><div class="markdown"><h1 id="run-stable-diffusion-webui-on-ubuntu-2204-with-rx-7900-xtx-and-rocm-55"><a aria-hidden="true" tabindex="-1" href="#run-stable-diffusion-webui-on-ubuntu-2204-with-rx-7900-xtx-and-rocm-55"><span class="icon icon-link"></span></a>Run stable-diffusion-webui on Ubuntu 22.04 with RX 7900 XTX and ROCm 5.5</h1>
<p>Yesterday I was regularly checking ROCm PRs, and surprised to discover that the ROCm 5.5.0 release notes had been merged, providing official support for my RTX 7900 XTX after a weeks-long wait. I can't wait to test it out.</p>
<h2 id="prerequisites"><a aria-hidden="true" tabindex="-1" href="#prerequisites"><span class="icon icon-link"></span></a>Prerequisites</h2>
<h3 id="install-amdgpu-driver"><a aria-hidden="true" tabindex="-1" href="#install-amdgpu-driver"><span class="icon icon-link"></span></a>Install AMDGPU driver</h3>
<pre><code class="language-bash"># grab the latest amdgpu-install package
curl -O https://repo.radeon.com/amdgpu-install/5.5/ubuntu/jammy/amdgpu-install_5.5.50500-1_all.deb

sudo dpkg -i amdgpu-install_5.5.50500-1_all.deb

# install AMDGPU with ROCm support (which is now 5.5.0)
sudo amdgpu-install --usecase=graphics,rocm

# you should see rocm-5.5.0 here
ls -l /opt

# grant device access to current user
# log in again or reboot should guarantee it works
sudo usermod -aG video $USER
sudo usermod -aG render $USER

# check rocm info, eg. the architecture
sudo rocminfo
# nvidia-smi alike
rocm-smi
</code></pre>
<h3 id="install-ubuntu-dependencies"><a aria-hidden="true" tabindex="-1" href="#install-ubuntu-dependencies"><span class="icon icon-link"></span></a>Install Ubuntu dependencies</h3>
<pre><code class="language-bash"># correct me if anything is missing
sudo apt install build-essential

sudo apt install python3-pip python3-venv

# fix &#x3C;cmath> not found
sudo apt install libstdc++-12-dev

# optional, suppress warnings from torchvision
sudo apt install libpng-dev libjpeg-dev
</code></pre>
<h3 id="enter-venv-environment"><a aria-hidden="true" tabindex="-1" href="#enter-venv-environment"><span class="icon icon-link"></span></a>Enter venv environment</h3>
<pre><code class="language-bash"># can be anywhere you prefer
mkdir ~/stable-diffusion
cd ~/stable-diffusion

python3 -m venv venv

# activate venv
source venv/bin/activate
</code></pre>
<h3 id="compile-pytorch-200"><a aria-hidden="true" tabindex="-1" href="#compile-pytorch-200"><span class="icon icon-link"></span></a>Compile pytorch 2.0.0</h3>
<pre><code class="language-bash"># must be in venv
cd ~/stable-diffusion
source venv/bin/activate

curl -L -O https://github.com/pytorch/pytorch/releases/download/v2.0.0/pytorch-v2.0.0.tar.gz
tar -xzvf pytorch-v2.0.0.tar.gz

cd pytorch-v2.0.0

# update the path to yours
export CMAKE_PREFIX_PATH="%HOME/stable-diffusion/venv"

export PYTORCH_ROCM_ARCH=gfx1100
export USE_CUDA=0

pip install cmake ninja
pip install -r requirements.txt
pip install mkl mkl-include
python3 tools/amd_build/build_amd.py
python3 setup.py install
</code></pre>
<h3 id="test-pytorch-functionality"><a aria-hidden="true" tabindex="-1" href="#test-pytorch-functionality"><span class="icon icon-link"></span></a>Test pytorch functionality</h3>
<p>Run <code>python3</code> and try these out:</p>
<pre><code class="language-python"># taken from https://github.com/RadeonOpenCompute/ROCm/issues/1930
import torch
torch.cuda.is_available()
torch.cuda.device_count()
torch.cuda.current_device()
torch.cuda.get_device_name(torch.cuda.current_device())

tensor = torch.randn(2, 2)
res = tensor.to(0)
# if it crashes, check this:
# https://github.com/RadeonOpenCompute/ROCm/issues/1930
print(res)
</code></pre>
<p>Or you can run <code>./test/run_test.py</code>, which I have failed in <code>test/profiler/test_profiler.py</code>, but it doesn't affect <code>stable-diffusion-webui</code> (hopefully).</p>
<h3 id="compile-torchvision-0151"><a aria-hidden="true" tabindex="-1" href="#compile-torchvision-0151"><span class="icon icon-link"></span></a>Compile torchvision 0.15.1</h3>
<pre><code class="language-bash"># must be in venv
cd ~/stable-diffusion
source venv/bin/activate

curl -L -O https://github.com/pytorch/vision/archive/refs/tags/v0.15.1.tar.gz
tar -xzvf v0.15.1.tar.gz

cd vision-0.15.1

# update the path to yours
export CMAKE_PREFIX_PATH="%HOME/stable-diffusion/venv"

# might be optional
export PYTORCH_ROCM_ARCH=gfx1100
export USE_CUDA=0

python3 setup.py install
</code></pre>
<h3 id="set-up-stable-diffusion-webui"><a aria-hidden="true" tabindex="-1" href="#set-up-stable-diffusion-webui"><span class="icon icon-link"></span></a>Set up stable-diffusion-webui</h3>
<pre><code class="language-bash"># must be in venv
cd ~/stable-diffusion
source venv/bin/activate

git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui

cd stable-diffusion-webui

# remove torch from requirements.txt
# idk if it is ok to skip
sed '/torch/d' requirements.txt

pip install -r requirements.txt

# might not be needed if there is only one gpu
export HIP_VISIBLE_DEVICES=0

python3 launch.py
</code></pre>
<h3 id="caveats"><a aria-hidden="true" tabindex="-1" href="#caveats"><span class="icon icon-link"></span></a>Caveats</h3>
<blockquote>
<p><code>CodeFormer</code> will raise exception when checking <code>pytorch</code>'s version, which is <code>2.0.0a0</code>, thus face restoration is unavailable for now.</p>
</blockquote>
<h3 id="conclusions"><a aria-hidden="true" tabindex="-1" href="#conclusions"><span class="icon icon-link"></span></a>Conclusions</h3>
<p>At first, I was building <code>pytorch</code> in Docker, with <a href="https://hub.docker.com/layers/rocm/composable_kernel/ck_ub20.04_rocm5.5/images/sha256-7ecc3b5e2e0104a58188ab5f26085c31815d2ed03955d66b805fc10d9e1f6873?context=explore">rocm/composable_kernel:ck_ub20.04_rocm5.5</a> as the base, but I encountered Segmentation Fault and didn't have the time to try again. Hopefully <a href="https://hub.docker.com/r/rocm/pytorch">rocm/pytorch</a> will update in recent days too.</p>
<p>Compared to ROCm 5.5 RC4 in Docker, ROCm 5.5 + bare installation does improve in stability and VRAM management. Performance can be optimized further, but I am satisfied now.</p>
<h2 id="references"><a aria-hidden="true" tabindex="-1" href="#references"><span class="icon icon-link"></span></a>References</h2>
<ul>
<li>https://gist.github.com/In-line/c1225f05d5164a4be9b39de68e99ee2b</li>
<li>https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/9591</li>
<li>https://github.com/RadeonOpenCompute/ROCm/issues/1930</li>
</ul></div></main></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"yyyymm":"202305","name":"run-stable-diffusion-webui-on-ubuntu-22.04-with-rx-7900-xtx-and-rocm-5.5","contentHtml":"\u003ch1 id=\"run-stable-diffusion-webui-on-ubuntu-2204-with-rx-7900-xtx-and-rocm-55\"\u003e\u003ca aria-hidden=\"true\" tabindex=\"-1\" href=\"#run-stable-diffusion-webui-on-ubuntu-2204-with-rx-7900-xtx-and-rocm-55\"\u003e\u003cspan class=\"icon icon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRun stable-diffusion-webui on Ubuntu 22.04 with RX 7900 XTX and ROCm 5.5\u003c/h1\u003e\n\u003cp\u003eYesterday I was regularly checking ROCm PRs, and surprised to discover that the ROCm 5.5.0 release notes had been merged, providing official support for my RTX 7900 XTX after a weeks-long wait. I can't wait to test it out.\u003c/p\u003e\n\u003ch2 id=\"prerequisites\"\u003e\u003ca aria-hidden=\"true\" tabindex=\"-1\" href=\"#prerequisites\"\u003e\u003cspan class=\"icon icon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePrerequisites\u003c/h2\u003e\n\u003ch3 id=\"install-amdgpu-driver\"\u003e\u003ca aria-hidden=\"true\" tabindex=\"-1\" href=\"#install-amdgpu-driver\"\u003e\u003cspan class=\"icon icon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstall AMDGPU driver\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e# grab the latest amdgpu-install package\ncurl -O https://repo.radeon.com/amdgpu-install/5.5/ubuntu/jammy/amdgpu-install_5.5.50500-1_all.deb\n\nsudo dpkg -i amdgpu-install_5.5.50500-1_all.deb\n\n# install AMDGPU with ROCm support (which is now 5.5.0)\nsudo amdgpu-install --usecase=graphics,rocm\n\n# you should see rocm-5.5.0 here\nls -l /opt\n\n# grant device access to current user\n# log in again or reboot should guarantee it works\nsudo usermod -aG video $USER\nsudo usermod -aG render $USER\n\n# check rocm info, eg. the architecture\nsudo rocminfo\n# nvidia-smi alike\nrocm-smi\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"install-ubuntu-dependencies\"\u003e\u003ca aria-hidden=\"true\" tabindex=\"-1\" href=\"#install-ubuntu-dependencies\"\u003e\u003cspan class=\"icon icon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstall Ubuntu dependencies\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e# correct me if anything is missing\nsudo apt install build-essential\n\nsudo apt install python3-pip python3-venv\n\n# fix \u0026#x3C;cmath\u003e not found\nsudo apt install libstdc++-12-dev\n\n# optional, suppress warnings from torchvision\nsudo apt install libpng-dev libjpeg-dev\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"enter-venv-environment\"\u003e\u003ca aria-hidden=\"true\" tabindex=\"-1\" href=\"#enter-venv-environment\"\u003e\u003cspan class=\"icon icon-link\"\u003e\u003c/span\u003e\u003c/a\u003eEnter venv environment\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e# can be anywhere you prefer\nmkdir ~/stable-diffusion\ncd ~/stable-diffusion\n\npython3 -m venv venv\n\n# activate venv\nsource venv/bin/activate\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"compile-pytorch-200\"\u003e\u003ca aria-hidden=\"true\" tabindex=\"-1\" href=\"#compile-pytorch-200\"\u003e\u003cspan class=\"icon icon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCompile pytorch 2.0.0\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e# must be in venv\ncd ~/stable-diffusion\nsource venv/bin/activate\n\ncurl -L -O https://github.com/pytorch/pytorch/releases/download/v2.0.0/pytorch-v2.0.0.tar.gz\ntar -xzvf pytorch-v2.0.0.tar.gz\n\ncd pytorch-v2.0.0\n\n# update the path to yours\nexport CMAKE_PREFIX_PATH=\"%HOME/stable-diffusion/venv\"\n\nexport PYTORCH_ROCM_ARCH=gfx1100\nexport USE_CUDA=0\n\npip install cmake ninja\npip install -r requirements.txt\npip install mkl mkl-include\npython3 tools/amd_build/build_amd.py\npython3 setup.py install\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"test-pytorch-functionality\"\u003e\u003ca aria-hidden=\"true\" tabindex=\"-1\" href=\"#test-pytorch-functionality\"\u003e\u003cspan class=\"icon icon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTest pytorch functionality\u003c/h3\u003e\n\u003cp\u003eRun \u003ccode\u003epython3\u003c/code\u003e and try these out:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# taken from https://github.com/RadeonOpenCompute/ROCm/issues/1930\nimport torch\ntorch.cuda.is_available()\ntorch.cuda.device_count()\ntorch.cuda.current_device()\ntorch.cuda.get_device_name(torch.cuda.current_device())\n\ntensor = torch.randn(2, 2)\nres = tensor.to(0)\n# if it crashes, check this:\n# https://github.com/RadeonOpenCompute/ROCm/issues/1930\nprint(res)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOr you can run \u003ccode\u003e./test/run_test.py\u003c/code\u003e, which I have failed in \u003ccode\u003etest/profiler/test_profiler.py\u003c/code\u003e, but it doesn't affect \u003ccode\u003estable-diffusion-webui\u003c/code\u003e (hopefully).\u003c/p\u003e\n\u003ch3 id=\"compile-torchvision-0151\"\u003e\u003ca aria-hidden=\"true\" tabindex=\"-1\" href=\"#compile-torchvision-0151\"\u003e\u003cspan class=\"icon icon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCompile torchvision 0.15.1\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e# must be in venv\ncd ~/stable-diffusion\nsource venv/bin/activate\n\ncurl -L -O https://github.com/pytorch/vision/archive/refs/tags/v0.15.1.tar.gz\ntar -xzvf v0.15.1.tar.gz\n\ncd vision-0.15.1\n\n# update the path to yours\nexport CMAKE_PREFIX_PATH=\"%HOME/stable-diffusion/venv\"\n\n# might be optional\nexport PYTORCH_ROCM_ARCH=gfx1100\nexport USE_CUDA=0\n\npython3 setup.py install\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"set-up-stable-diffusion-webui\"\u003e\u003ca aria-hidden=\"true\" tabindex=\"-1\" href=\"#set-up-stable-diffusion-webui\"\u003e\u003cspan class=\"icon icon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSet up stable-diffusion-webui\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e# must be in venv\ncd ~/stable-diffusion\nsource venv/bin/activate\n\ngit clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n\ncd stable-diffusion-webui\n\n# remove torch from requirements.txt\n# idk if it is ok to skip\nsed '/torch/d' requirements.txt\n\npip install -r requirements.txt\n\n# might not be needed if there is only one gpu\nexport HIP_VISIBLE_DEVICES=0\n\npython3 launch.py\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"caveats\"\u003e\u003ca aria-hidden=\"true\" tabindex=\"-1\" href=\"#caveats\"\u003e\u003cspan class=\"icon icon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCaveats\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003ccode\u003eCodeFormer\u003c/code\u003e will raise exception when checking \u003ccode\u003epytorch\u003c/code\u003e's version, which is \u003ccode\u003e2.0.0a0\u003c/code\u003e, thus face restoration is unavailable for now.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"conclusions\"\u003e\u003ca aria-hidden=\"true\" tabindex=\"-1\" href=\"#conclusions\"\u003e\u003cspan class=\"icon icon-link\"\u003e\u003c/span\u003e\u003c/a\u003eConclusions\u003c/h3\u003e\n\u003cp\u003eAt first, I was building \u003ccode\u003epytorch\u003c/code\u003e in Docker, with \u003ca href=\"https://hub.docker.com/layers/rocm/composable_kernel/ck_ub20.04_rocm5.5/images/sha256-7ecc3b5e2e0104a58188ab5f26085c31815d2ed03955d66b805fc10d9e1f6873?context=explore\"\u003erocm/composable_kernel:ck_ub20.04_rocm5.5\u003c/a\u003e as the base, but I encountered Segmentation Fault and didn't have the time to try again. Hopefully \u003ca href=\"https://hub.docker.com/r/rocm/pytorch\"\u003erocm/pytorch\u003c/a\u003e will update in recent days too.\u003c/p\u003e\n\u003cp\u003eCompared to ROCm 5.5 RC4 in Docker, ROCm 5.5 + bare installation does improve in stability and VRAM management. Performance can be optimized further, but I am satisfied now.\u003c/p\u003e\n\u003ch2 id=\"references\"\u003e\u003ca aria-hidden=\"true\" tabindex=\"-1\" href=\"#references\"\u003e\u003cspan class=\"icon icon-link\"\u003e\u003c/span\u003e\u003c/a\u003eReferences\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003ehttps://gist.github.com/In-line/c1225f05d5164a4be9b39de68e99ee2b\u003c/li\u003e\n\u003cli\u003ehttps://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/9591\u003c/li\u003e\n\u003cli\u003ehttps://github.com/RadeonOpenCompute/ROCm/issues/1930\u003c/li\u003e\n\u003c/ul\u003e","title":"Run stable-diffusion-webui on Ubuntu 22.04 with RX 7900 XTX and ROCm 5.5"}},"__N_SSG":true},"page":"/post/[...routes]","query":{"routes":["202305","run-stable-diffusion-webui-on-ubuntu-22.04-with-rx-7900-xtx-and-rocm-5.5"]},"buildId":"HkcMTPpvc8PJ5ksTEEHTj","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>